# Заключительное задание первого модуля

Ваша задача в этом уроке — загрузить данные в Elasticsearch из PostgreSQL. Подробности задания в папке `etl`.

# Описание проекта

Приложение для переноса данных из `Elasticsearch` в `PostgreSQL`. 

Основные модули:
- `PG Extractor` - батчами выгружает все необхдоимые данные из `PostgreSQL` одним SQL запросом;
- `Transformer` - преобразует выгруженные из `PostgreSQL` данные в pydantic-класс;
- `ES Loader` - загружает преобразованные данные в `Elasticsearch`.

Для отказоусточивости работы приложения используется механизм `backoff`, увеличивающий интервалы между попытками подключения к ресурсу. В данном проекте `backoff` используется при подключении к `PostgreSQL` и `Elasticsearch`, экспоненциально увеличивая интервалы между подключениями после получения любого исключения (класс `Exception`).

Для хранения состояния используется локальное json-хранилище, куда записывается информация о последней обработанной записи.

# Требования
- [Docker](https://www.docker.com/)


# Запуск проекта

Для запуска проекта необходимо в корне каталога с проектом создать файл `.env`. `env-файл` должен повторять структуру файла `.env.example` и содержать корректные данные для вашего проекта. 

Сам запуск осуществляется командой `docker-compose up -d`. После запуска этой команды поднимутся 3 контейнера: контейнер с source базой данных PostgreSQL, контейнер с target базой данных Elasticsearch и контейнер с python приложением, осуществляющим перенос данных из PostgreSQL в Elasticsearch. При запуске контейнера с базой данных Postgres запускаются в алфавитном порядке sql-скрипты из директории `init_scripts`, которые создают схему, таблицы и наполняют таблицы данными.

В `docker-compose.yaml` описаны настройки для запуска этих контейнеров. При необходимости, вы можете изменить некоторые настройки. 
